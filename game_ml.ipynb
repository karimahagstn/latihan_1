{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONn6Nf7x2m3QDZXeWyydZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimahagstn/latihan_1/blob/main/game_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dxJaCeHLfg14"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "Pkqqj6LLfo6o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DYPBadUfsXe",
        "outputId": "daa39aac-6e89-476a-f785-e6e6e29f02d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_map = [\n",
        "    \"HFSF\",\n",
        "    \"HFFH\",\n",
        "    \"FFFH\",\n",
        "    \"HFFG\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eDmqE9ofu3S",
        "outputId": "b1eaae82-f95e-403d-9f96-026be71a5fa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYubxYKxfx2C",
        "outputId": "ccbbde8e-7a30-41a8-eaa4-a5aada8b0156"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 16\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.9\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ],
      "metadata": {
        "id": "pyz6OQcSf1d0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXKsyalxf4kg",
        "outputId": "796614cc-1396-43fd-da40-2963a976d11d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 906 episode and 2 step\n",
            "Delta Q = 0.9535315050003464\n",
            "Q_table[3,3]_old = 0.516633178254435\n",
            "Q_table[(3, 3)]_new = 0.518501365429338\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 906 episode and 3 step\n",
            "Delta Q = 0.9535315050003464\n",
            "Q_table[3,3]_old = 0.518501365429338\n",
            "Q_table[(3, 3)]_new = 0.5201827338867506\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 906 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 0 step\n",
            "Delta Q = 0.9676713395016171\n",
            "Q_table[0,1]_old = 0.6696539778969063\n",
            "Q_table[(0, 1)]_new = 0.6703599196088328\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 1 step\n",
            "Delta Q = 0.9768062764383347\n",
            "Q_table[6,1]_old = 0.7519037722401893\n",
            "Q_table[(6, 1)]_new = 0.7535196714545052\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 2 step\n",
            "Delta Q = 0.9872187161055631\n",
            "Q_table[10,1]_old = 0.8534030715370527\n",
            "Q_table[(10, 1)]_new = 0.8552814804889106\n",
            "We are on 10 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 3 step\n",
            "Delta Q = 0.9714929495003299\n",
            "Q_table[14,0]_old = 0.6213243603700366\n",
            "Q_table[(14, 0)]_new = 0.6306848738333628\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 4 step\n",
            "Delta Q = 0.964438567653696\n",
            "Q_table[13,3]_old = 0.4974109005727606\n",
            "Q_table[(13, 3)]_new = 0.5121083781691804\n",
            "We are on 13 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 5 step\n",
            "Delta Q = 0.9714929495003299\n",
            "Q_table[9,1]_old = 0.5196043035107518\n",
            "Q_table[(9, 1)]_new = 0.5391368226600066\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 6 step\n",
            "Delta Q = 0.9714929495003299\n",
            "Q_table[13,1]_old = 0.5016088274439392\n",
            "Q_table[(13, 1)]_new = 0.5229408941998752\n",
            "We are on 13 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 7 step\n",
            "Delta Q = 0.9872187161055631\n",
            "Q_table[13,2]_old = 0.7943661055592214\n",
            "Q_table[(13, 2)]_new = 0.8021482111088624\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 8 step\n",
            "Delta Q = 1.0\n",
            "Q_table[14,2]_old = 0.9690968456173673\n",
            "Q_table[(14, 2)]_new = 0.9721871610556305\n",
            "We are on 14 state\n",
            "And now we are on 15 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 908 episode and 0 step\n",
            "Delta Q = 0.9532093924583868\n",
            "Q_table[0,0]_old = 0.5225216171885211\n",
            "Q_table[(0, 0)]_new = 0.5234788479280557\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 908 episode and 1 step\n",
            "Delta Q = 0.960332392764795\n",
            "Q_table[1,0]_old = 0.5878299330399261\n",
            "Q_table[(1, 0)]_new = 0.5893793325007285\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 0 step\n",
            "Delta Q = 0.9604300024557032\n",
            "Q_table[0,3]_old = 0.594429696685878\n",
            "Q_table[(0, 3)]_new = 0.5954167294729934\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 1 step\n",
            "Delta Q = 0.9532093924583868\n",
            "Q_table[2,0]_old = 0.5246599460452087\n",
            "Q_table[(2, 0)]_new = 0.5254033438990746\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 2 step\n",
            "Delta Q = 0.9604300024557032\n",
            "Q_table[1,2]_old = 0.5912154717598526\n",
            "Q_table[(1, 2)]_new = 0.5925239270395705\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 3 step\n",
            "Delta Q = 0.9604300024557032\n",
            "Q_table[2,3]_old = 0.5951055040875827\n",
            "Q_table[(2, 3)]_new = 0.5960249561345276\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 4 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[2,1]_old = 0.6714444717300356\n",
            "Q_table[(2, 1)]_new = 0.6721167949879376\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 5 step\n",
            "Delta Q = 0.9580667046370416\n",
            "Q_table[6,0]_old = 0.5609135457225773\n",
            "Q_table[(6, 0)]_new = 0.5628888957873612\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 6 step\n",
            "Delta Q = 0.9533271534335613\n",
            "Q_table[5,3]_old = 0.5011907719980152\n",
            "Q_table[(5, 3)]_new = 0.504398848231775\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 7 step\n",
            "Delta Q = 0.9580667046370416\n",
            "Q_table[1,1]_old = 0.5625911990493964\n",
            "Q_table[(1, 1)]_new = 0.5643987837814983\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 0 step\n",
            "Delta Q = 0.9533271534335613\n",
            "Q_table[0,0]_old = 0.5234788479280557\n",
            "Q_table[(0, 0)]_new = 0.5244581165688115\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 1 step\n",
            "Delta Q = 0.9604905115489144\n",
            "Q_table[1,2]_old = 0.5925239270395705\n",
            "Q_table[(1, 2)]_new = 0.5937620458845279\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 2 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[2,1]_old = 0.6721167949879376\n",
            "Q_table[(2, 1)]_new = 0.6727218859200494\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 3 step\n",
            "Delta Q = 0.9605449697328045\n",
            "Q_table[6,3]_old = 0.5913544296790656\n",
            "Q_table[(6, 3)]_new = 0.5927639564439635\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 4 step\n",
            "Delta Q = 0.9605449697328045\n",
            "Q_table[2,3]_old = 0.5960249561345276\n",
            "Q_table[(2, 3)]_new = 0.5969674302538792\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 5 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[2,1]_old = 0.6727218859200494\n",
            "Q_table[(2, 1)]_new = 0.67326646775895\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 6 step\n",
            "Delta Q = 0.9580667046370416\n",
            "Q_table[6,0]_old = 0.5628888957873612\n",
            "Q_table[(6, 0)]_new = 0.5646667108456667\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 0 step\n",
            "Delta Q = 0.9605939820983055\n",
            "Q_table[0,3]_old = 0.5954167294729934\n",
            "Q_table[(0, 3)]_new = 0.5964690386239996\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 1 step\n",
            "Delta Q = 0.9534385841296076\n",
            "Q_table[2,0]_old = 0.5254033438990746\n",
            "Q_table[(2, 0)]_new = 0.5263015936387747\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 2 step\n",
            "Delta Q = 0.9534385841296076\n",
            "Q_table[1,3]_old = 0.5251381752388024\n",
            "Q_table[(1, 3)]_new = 0.5260629418445296\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 3 step\n",
            "Delta Q = 0.9605939820983055\n",
            "Q_table[1,2]_old = 0.5937620458845279\n",
            "Q_table[(1, 2)]_new = 0.5949798233943806\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 4 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[2,1]_old = 0.67326646775895\n",
            "Q_table[(2, 1)]_new = 0.6737565914139606\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 5 step\n",
            "Delta Q = 0.9580667046370416\n",
            "Q_table[6,0]_old = 0.5646667108456667\n",
            "Q_table[(6, 0)]_new = 0.5662667443981416\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 6 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[5,2]_old = 0.6451856070782391\n",
            "Q_table[(5, 2)]_new = 0.6484838168013207\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 0 step\n",
            "Delta Q = 0.9535315050003464\n",
            "Q_table[0,2]_old = 0.5212540776271466\n",
            "Q_table[(0, 2)]_new = 0.5226601748647784\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 1 step\n",
            "Delta Q = 0.9606380932272565\n",
            "Q_table[3,0]_old = 0.5947945000038496\n",
            "Q_table[(3, 0)]_new = 0.5959531432307211\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 2 step\n",
            "Delta Q = 0.9535481841054942\n",
            "Q_table[2,0]_old = 0.5263015936387747\n",
            "Q_table[(2, 0)]_new = 0.5272196183803916\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 3 step\n",
            "Delta Q = 0.9606380932272565\n",
            "Q_table[1,2]_old = 0.5949798233943806\n",
            "Q_table[(1, 2)]_new = 0.596119934282199\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 4 step\n",
            "Delta Q = 0.9536357828907649\n",
            "Q_table[2,2]_old = 0.5265427196280236\n",
            "Q_table[(2, 2)]_new = 0.5275242305559861\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 0 step\n",
            "Delta Q = 0.9536357828907649\n",
            "Q_table[0,2]_old = 0.5226601748647784\n",
            "Q_table[(0, 2)]_new = 0.5240299402690655\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 914 episode and 0 step\n",
            "Delta Q = 0.953650794085398\n",
            "Q_table[0,0]_old = 0.5244581165688115\n",
            "Q_table[(0, 0)]_new = 0.5256630989973283\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 914 episode and 1 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[1,1]_old = 0.5643987837814983\n",
            "Q_table[(1, 1)]_new = 0.5663224489154675\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 914 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 915 episode and 0 step\n",
            "Delta Q = 0.953650794085398\n",
            "Q_table[0,0]_old = 0.5256630989973283\n",
            "Q_table[(0, 0)]_new = 0.5267475831829934\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 915 episode and 1 step\n",
            "Delta Q = 0.9606380932272565\n",
            "Q_table[1,2]_old = 0.596119934282199\n",
            "Q_table[(1, 2)]_new = 0.5971460340812356\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 915 episode and 2 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[2,1]_old = 0.6737565914139606\n",
            "Q_table[(2, 1)]_new = 0.67419770270347\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 915 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 0 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[0,1]_old = 0.6703599196088328\n",
            "Q_table[(0, 1)]_new = 0.671140698078855\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 0 step\n",
            "Delta Q = 0.9537431430673112\n",
            "Q_table[0,0]_old = 0.5267475831829934\n",
            "Q_table[(0, 0)]_new = 0.5278159679320054\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 1 step\n",
            "Delta Q = 0.9537431430673112\n",
            "Q_table[1,3]_old = 0.5260629418445296\n",
            "Q_table[(1, 3)]_new = 0.5271997907273879\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 2 step\n",
            "Delta Q = 0.9537431430673112\n",
            "Q_table[1,3]_old = 0.5271997907273879\n",
            "Q_table[(1, 3)]_new = 0.5282229547219603\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 3 step\n",
            "Delta Q = 0.9606777932433124\n",
            "Q_table[1,2]_old = 0.5971460340812356\n",
            "Q_table[(1, 2)]_new = 0.5981092239164244\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 4 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[2,0]_old = 0.5272196183803916\n",
            "Q_table[(2, 0)]_new = 0.5283274866948307\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 5 step\n",
            "Delta Q = 0.960402662827097\n",
            "Q_table[1,0]_old = 0.5893793325007285\n",
            "Q_table[(1, 0)]_new = 0.5908440620777526\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 918 episode and 0 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[0,0]_old = 0.5278159679320054\n",
            "Q_table[(0, 0)]_new = 0.528864201291283\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 918 episode and 1 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[1,3]_old = 0.5282229547219603\n",
            "Q_table[(1, 3)]_new = 0.5292304894022425\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 918 episode and 2 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[1,1]_old = 0.5663224489154675\n",
            "Q_table[(1, 1)]_new = 0.5680537475360397\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 918 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 919 episode and 0 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[0,1]_old = 0.671140698078855\n",
            "Q_table[(0, 1)]_new = 0.671843398701875\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 919 episode and 1 step\n",
            "Delta Q = 0.9606777932433124\n",
            "Q_table[6,3]_old = 0.5927639564439635\n",
            "Q_table[(6, 3)]_new = 0.5941653540428795\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 919 episode and 2 step\n",
            "Delta Q = 0.9678167704309055\n",
            "Q_table[2,1]_old = 0.67419770270347\n",
            "Q_table[(2, 1)]_new = 0.6745947028640286\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 919 episode and 3 step\n",
            "Delta Q = 0.976975333244002\n",
            "Q_table[6,1]_old = 0.7535196714545052\n",
            "Q_table[(6, 1)]_new = 0.7551430375530567\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 919 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 920 episode and 0 step\n",
            "Delta Q = 0.9607135232577626\n",
            "Q_table[0,3]_old = 0.5964690386239996\n",
            "Q_table[(0, 3)]_new = 0.5975356580193623\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 920 episode and 1 step\n",
            "Delta Q = 0.9679628733797752\n",
            "Q_table[2,1]_old = 0.6745947028640286\n",
            "Q_table[(2, 1)]_new = 0.6750981059574008\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 920 episode and 2 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[6,0]_old = 0.5662667443981416\n",
            "Q_table[(6, 0)]_new = 0.5680036134704463\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 920 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 0 step\n",
            "Delta Q = 0.9536357828907649\n",
            "Q_table[0,2]_old = 0.5240299402690655\n",
            "Q_table[(0, 2)]_new = 0.5252627291329238\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 1 step\n",
            "Delta Q = 0.9607588295361661\n",
            "Q_table[3,0]_old = 0.5959531432307211\n",
            "Q_table[(3, 0)]_new = 0.5971166584438151\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 2 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[2,0]_old = 0.5283274866948307\n",
            "Q_table[(2, 0)]_new = 0.5293245681778258\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 3 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[1,3]_old = 0.5292304894022425\n",
            "Q_table[(1, 3)]_new = 0.5301372706144964\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 4 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[1,1]_old = 0.5680537475360397\n",
            "Q_table[(1, 1)]_new = 0.5696119162945545\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 5 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[5,3]_old = 0.504398848231775\n",
            "Q_table[(5, 3)]_new = 0.5077887935610758\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 6 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[1,1]_old = 0.5696119162945545\n",
            "Q_table[(1, 1)]_new = 0.5710142681772179\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 7 step\n",
            "Delta Q = 0.9538298301524782\n",
            "Q_table[5,3]_old = 0.5077887935610758\n",
            "Q_table[(5, 3)]_new = 0.5108397443574464\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 8 step\n",
            "Delta Q = 0.9607588295361661\n",
            "Q_table[1,2]_old = 0.5981092239164244\n",
            "Q_table[(1, 2)]_new = 0.599057131060948\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 9 step\n",
            "Delta Q = 0.9537404992599434\n",
            "Q_table[2,2]_old = 0.5275242305559861\n",
            "Q_table[(2, 2)]_new = 0.5285123067603309\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 10 step\n",
            "Delta Q = 0.9607588295361661\n",
            "Q_table[3,0]_old = 0.5971166584438151\n",
            "Q_table[(3, 0)]_new = 0.5981638221355997\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 11 step\n",
            "Delta Q = 0.9679628733797752\n",
            "Q_table[2,1]_old = 0.6750981059574008\n",
            "Q_table[(2, 1)]_new = 0.675551168741436\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 12 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[6,0]_old = 0.5680036134704463\n",
            "Q_table[(6, 0)]_new = 0.5695667956355206\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 0 step\n",
            "Delta Q = 0.9607996051867292\n",
            "Q_table[0,3]_old = 0.5975356580193623\n",
            "Q_table[(0, 3)]_new = 0.5985816974041552\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 1 step\n",
            "Delta Q = 0.953834743992204\n",
            "Q_table[2,2]_old = 0.5285123067603309\n",
            "Q_table[(2, 2)]_new = 0.5294958200765018\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 2 step\n",
            "Delta Q = 0.9607996051867292\n",
            "Q_table[3,0]_old = 0.5981638221355997\n",
            "Q_table[(3, 0)]_new = 0.5991470451087689\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 3 step\n",
            "Delta Q = 0.9607996051867292\n",
            "Q_table[2,3]_old = 0.5969674302538792\n",
            "Q_table[(2, 3)]_new = 0.5980702924152206\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 4 step\n",
            "Delta Q = 0.9607996051867292\n",
            "Q_table[2,3]_old = 0.5980702924152206\n",
            "Q_table[(2, 3)]_new = 0.5990628683604278\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 5 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[2,0]_old = 0.5293245681778258\n",
            "Q_table[(2, 0)]_new = 0.5303072531555285\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 6 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[1,3]_old = 0.5301372706144964\n",
            "Q_table[(1, 3)]_new = 0.5310386853485322\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 7 step\n",
            "Delta Q = 0.9604659058831688\n",
            "Q_table[1,0]_old = 0.5908440620777526\n",
            "Q_table[(1, 0)]_new = 0.5922255617531462\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 0 step\n",
            "Delta Q = 0.9607996051867292\n",
            "Q_table[0,3]_old = 0.5985816974041552\n",
            "Q_table[(0, 3)]_new = 0.599523132850469\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 1 step\n",
            "Delta Q = 0.9679628733797752\n",
            "Q_table[2,1]_old = 0.675551168741436\n",
            "Q_table[(2, 1)]_new = 0.6759589252470675\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 2 step\n",
            "Delta Q = 0.9583635435121189\n",
            "Q_table[6,0]_old = 0.5695667956355206\n",
            "Q_table[(6, 0)]_new = 0.5709736595840875\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 3 step\n",
            "Delta Q = 0.9679628733797752\n",
            "Q_table[5,2]_old = 0.6484838168013207\n",
            "Q_table[(5, 2)]_new = 0.6515983085009638\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 4 step\n",
            "Delta Q = 0.9608363032722361\n",
            "Q_table[6,3]_old = 0.5941653540428795\n",
            "Q_table[(6, 3)]_new = 0.5955851219108277\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 5 step\n",
            "Delta Q = 0.9679628733797752\n",
            "Q_table[2,1]_old = 0.6759589252470675\n",
            "Q_table[(2, 1)]_new = 0.6763259061021358\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 6 step\n",
            "Delta Q = 0.9608693315491923\n",
            "Q_table[6,3]_old = 0.5955851219108277\n",
            "Q_table[(6, 3)]_new = 0.5968959412689372\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 7 step\n",
            "Delta Q = 0.9608693315491923\n",
            "Q_table[2,3]_old = 0.5990628683604278\n",
            "Q_table[(2, 3)]_new = 0.6000259130735773\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 8 step\n",
            "Delta Q = 0.9679628733797752\n",
            "Q_table[2,1]_old = 0.6763259061021358\n",
            "Q_table[(2, 1)]_new = 0.6766561888716974\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 9 step\n",
            "Delta Q = 0.976975333244002\n",
            "Q_table[6,1]_old = 0.7551430375530567\n",
            "Q_table[(6, 1)]_new = 0.756604067041753\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 10 step\n",
            "Delta Q = 0.964438567653696\n",
            "Q_table[10,0]_old = 0.569586153908145\n",
            "Q_table[(10, 0)]_new = 0.5770661061710265\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 11 step\n",
            "Delta Q = 0.976975333244002\n",
            "Q_table[9,2]_old = 0.7159840850410653\n",
            "Q_table[(9, 2)]_new = 0.7213610097809607\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 924 episode and 0 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[0,0]_old = 0.528864201291283\n",
            "Q_table[(0, 0)]_new = 0.52989292295764\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 924 episode and 1 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[1,1]_old = 0.5710142681772179\n",
            "Q_table[(1, 1)]_new = 0.5725566891245828\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 924 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 0 step\n",
            "Delta Q = 0.9608990569984528\n",
            "Q_table[0,3]_old = 0.599523132850469\n",
            "Q_table[(0, 3)]_new = 0.6004698765638748\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 1 step\n",
            "Delta Q = 0.9539232340597892\n",
            "Q_table[2,2]_old = 0.5294958200765018\n",
            "Q_table[(2, 2)]_new = 0.5304694721286408\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 2 step\n",
            "Delta Q = 0.9539232340597892\n",
            "Q_table[3,2]_old = 0.5179008212436007\n",
            "Q_table[(3, 2)]_new = 0.5200339731790299\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 0 step\n",
            "Delta Q = 0.9539232340597892\n",
            "Q_table[0,2]_old = 0.5252627291329238\n",
            "Q_table[(0, 2)]_new = 0.5266596902794206\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 1 step\n",
            "Delta Q = 0.9539232340597892\n",
            "Q_table[3,2]_old = 0.5200339731790299\n",
            "Q_table[(3, 2)]_new = 0.5219538099209161\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 2 step\n",
            "Delta Q = 0.9539232340597892\n",
            "Q_table[3,3]_old = 0.5201827338867506\n",
            "Q_table[(3, 3)]_new = 0.5220876945578647\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 3 step\n",
            "Delta Q = 0.9608990569984528\n",
            "Q_table[3,0]_old = 0.5991470451087689\n",
            "Q_table[(3, 0)]_new = 0.6001313975963448\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 4 step\n",
            "Delta Q = 0.9680943660337578\n",
            "Q_table[2,1]_old = 0.6766561888716974\n",
            "Q_table[(2, 1)]_new = 0.6770849360182855\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 5 step\n",
            "Delta Q = 0.976975333244002\n",
            "Q_table[6,1]_old = 0.756604067041753\n",
            "Q_table[(6, 1)]_new = 0.7579189935815797\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 927 episode and 0 step\n",
            "Delta Q = 0.954011825783671\n",
            "Q_table[0,2]_old = 0.5266596902794206\n",
            "Q_table[(0, 2)]_new = 0.5280055470351496\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 927 episode and 1 step\n",
            "Delta Q = 0.9609376442416457\n",
            "Q_table[3,0]_old = 0.6001313975963448\n",
            "Q_table[(3, 0)]_new = 0.601055902078356\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 927 episode and 2 step\n",
            "Delta Q = 0.9682127094223422\n",
            "Q_table[2,1]_old = 0.6770849360182855\n",
            "Q_table[(2, 1)]_new = 0.6775891518387991\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 927 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 0 step\n",
            "Delta Q = 0.9682127094223422\n",
            "Q_table[0,1]_old = 0.671843398701875\n",
            "Q_table[(0, 1)]_new = 0.6728717682540297\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 1 step\n",
            "Delta Q = 0.9609830236654919\n",
            "Q_table[6,3]_old = 0.5968959412689372\n",
            "Q_table[(6, 3)]_new = 0.5981893708075354\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 2 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[2,0]_old = 0.5303072531555285\n",
            "Q_table[(2, 0)]_new = 0.5311916696354609\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 3 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[1,3]_old = 0.5310386853485322\n",
            "Q_table[(1, 3)]_new = 0.5318499586091643\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 4 step\n",
            "Delta Q = 0.9605584591428626\n",
            "Q_table[1,0]_old = 0.5922255617531462\n",
            "Q_table[(1, 0)]_new = 0.5935614647206944\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 929 episode and 0 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[0,0]_old = 0.52989292295764\n",
            "Q_table[(0, 0)]_new = 0.5308187724573613\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 929 episode and 1 step\n",
            "Delta Q = 0.9605584591428626\n",
            "Q_table[1,0]_old = 0.5935614647206944\n",
            "Q_table[(1, 0)]_new = 0.5947637773914876\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 930 episode and 0 step\n",
            "Delta Q = 0.9609830236654919\n",
            "Q_table[0,3]_old = 0.6004698765638748\n",
            "Q_table[(0, 3)]_new = 0.6014059125729793\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 930 episode and 1 step\n",
            "Delta Q = 0.9540950311870521\n",
            "Q_table[2,2]_old = 0.5304694721286408\n",
            "Q_table[(2, 2)]_new = 0.5315175561028288\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 930 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 0 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[0,0]_old = 0.5308187724573613\n",
            "Q_table[(0, 0)]_new = 0.5316520370071105\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 1 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[1,1]_old = 0.5725566891245828\n",
            "Q_table[(1, 1)]_new = 0.5739448679772112\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 0 step\n",
            "Delta Q = 0.9682127094223422\n",
            "Q_table[0,1]_old = 0.6728717682540297\n",
            "Q_table[(0, 1)]_new = 0.6737973008509689\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 1 step\n",
            "Delta Q = 0.976975333244002\n",
            "Q_table[6,1]_old = 0.7579189935815797\n",
            "Q_table[(6, 1)]_new = 0.7591024274674236\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 2 step\n",
            "Delta Q = 0.9874968444950067\n",
            "Q_table[10,1]_old = 0.8552814804889106\n",
            "Q_table[(10, 1)]_new = 0.8572501769350263\n",
            "We are on 10 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 3 step\n",
            "Delta Q = 0.9721933389997977\n",
            "Q_table[14,0]_old = 0.6306848738333628\n",
            "Q_table[(14, 0)]_new = 0.6398097254498242\n",
            "We are on 14 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 4 step\n",
            "Delta Q = 0.9721933389997977\n",
            "Q_table[13,1]_old = 0.5229408941998752\n",
            "Q_table[(13, 1)]_new = 0.5428401437796853\n",
            "We are on 13 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 5 step\n",
            "Delta Q = 0.9649224908802865\n",
            "Q_table[13,3]_old = 0.5121083781691804\n",
            "Q_table[(13, 3)]_new = 0.5258200312325488\n",
            "We are on 13 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 6 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[9,3]_old = 0.45063368033059953\n",
            "Q_table[(9, 3)]_new = 0.46421416006262634\n",
            "We are on 9 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 7 step\n",
            "Delta Q = 0.9649224908802865\n",
            "Q_table[5,1]_old = 0.5881310497923509\n",
            "Q_table[(5, 1)]_new = 0.5942404356934022\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 8 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[9,3]_old = 0.46421416006262634\n",
            "Q_table[(9, 3)]_new = 0.47643659182145043\n",
            "We are on 9 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 0 step\n",
            "Delta Q = 0.9609830236654919\n",
            "Q_table[0,3]_old = 0.6014059125729793\n",
            "Q_table[(0, 3)]_new = 0.6022483449811733\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 1 step\n",
            "Delta Q = 0.9683192184720681\n",
            "Q_table[2,1]_old = 0.6775891518387991\n",
            "Q_table[(2, 1)]_new = 0.6781494551269873\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 2 step\n",
            "Delta Q = 0.9610334509614289\n",
            "Q_table[6,3]_old = 0.5981893708075354\n",
            "Q_table[(6, 3)]_new = 0.5994038846882108\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 3 step\n",
            "Delta Q = 0.9610334509614289\n",
            "Q_table[2,3]_old = 0.6000259130735773\n",
            "Q_table[(2, 3)]_new = 0.6010567727276485\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 4 step\n",
            "Delta Q = 0.9683192184720681\n",
            "Q_table[2,1]_old = 0.6781494551269873\n",
            "Q_table[(2, 1)]_new = 0.6786537280863567\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 5 step\n",
            "Delta Q = 0.9771525159241524\n",
            "Q_table[6,1]_old = 0.7591024274674236\n",
            "Q_table[(6, 1)]_new = 0.7603447006448337\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 6 step\n",
            "Delta Q = 0.9684310230580351\n",
            "Q_table[10,3]_old = 0.6446499987915837\n",
            "Q_table[(10, 3)]_new = 0.6486160219704604\n",
            "We are on 10 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 7 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[6,0]_old = 0.5709736595840875\n",
            "Q_table[(6, 0)]_new = 0.5725201413907655\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 8 step\n",
            "Delta Q = 0.9649224908802865\n",
            "Q_table[5,1]_old = 0.5942404356934022\n",
            "Q_table[(5, 1)]_new = 0.5997388830043485\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 9 step\n",
            "Delta Q = 0.9771525159241524\n",
            "Q_table[9,2]_old = 0.7213610097809607\n",
            "Q_table[(9, 2)]_new = 0.726377424727017\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 10 step\n",
            "Delta Q = 0.9684310230580351\n",
            "Q_table[10,3]_old = 0.6486160219704604\n",
            "Q_table[(10, 3)]_new = 0.6521854428314494\n",
            "We are on 10 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 11 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[6,0]_old = 0.5725201413907655\n",
            "Q_table[(6, 0)]_new = 0.5739119750167756\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 12 step\n",
            "Delta Q = 0.9653739682254315\n",
            "Q_table[5,1]_old = 0.5997388830043485\n",
            "Q_table[(5, 1)]_new = 0.6051389629293452\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 13 step\n",
            "Delta Q = 0.9721933389997977\n",
            "Q_table[9,1]_old = 0.5391368226600066\n",
            "Q_table[(9, 1)]_new = 0.5574164793938036\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 14 step\n",
            "Delta Q = 0.9653739682254315\n",
            "Q_table[13,3]_old = 0.5258200312325488\n",
            "Q_table[(13, 3)]_new = 0.5386119963347255\n",
            "We are on 13 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 15 step\n",
            "Delta Q = 0.9721933389997977\n",
            "Q_table[9,1]_old = 0.5574164793938036\n",
            "Q_table[(9, 1)]_new = 0.5738681704542209\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 16 step\n",
            "Delta Q = 0.9653739682254315\n",
            "Q_table[13,3]_old = 0.5386119963347255\n",
            "Q_table[(13, 3)]_new = 0.5501247649266845\n",
            "We are on 13 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 17 step\n",
            "Delta Q = 0.9307395765833794\n",
            "Q_table[9,0]_old = 0.2589902899351045\n",
            "Q_table[(9, 0)]_new = 0.2638308375249734\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 18 step\n",
            "Delta Q = 0.9653739682254315\n",
            "Q_table[8,2]_old = 0.3415508509264373\n",
            "Q_table[(8, 2)]_new = 0.3727697340592251\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 19 step\n",
            "Delta Q = 0.9771525159241524\n",
            "Q_table[9,2]_old = 0.726377424727017\n",
            "Q_table[(9, 2)]_new = 0.7308921981784677\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 20 step\n",
            "Delta Q = 0.9657802978360621\n",
            "Q_table[10,0]_old = 0.5770661061710265\n",
            "Q_table[(10, 0)]_new = 0.585139793389986\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 21 step\n",
            "Delta Q = 0.9586438477650867\n",
            "Q_table[9,3]_old = 0.47643659182145043\n",
            "Q_table[(9, 3)]_new = 0.48743678040439214\n",
            "We are on 9 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 22 step\n",
            "Delta Q = 0.9684310230580351\n",
            "Q_table[5,2]_old = 0.6515983085009638\n",
            "Q_table[(5, 2)]_new = 0.6548695007089025\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 23 step\n",
            "Delta Q = 0.9589382550638013\n",
            "Q_table[6,0]_old = 0.5739119750167756\n",
            "Q_table[(6, 0)]_new = 0.5754590325788993\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 24 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[5,3]_old = 0.5108397443574464\n",
            "Q_table[(5, 3)]_new = 0.513670911717187\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 25 step\n",
            "Delta Q = 0.9589382550638013\n",
            "Q_table[1,1]_old = 0.5739448679772112\n",
            "Q_table[(1, 1)]_new = 0.5754886362432914\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 26 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 0 step\n",
            "Delta Q = 0.9610788355277722\n",
            "Q_table[0,3]_old = 0.6022483449811733\n",
            "Q_table[(0, 3)]_new = 0.603102346010828\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 1 step\n",
            "Delta Q = 0.9610788355277722\n",
            "Q_table[2,3]_old = 0.6010567727276485\n",
            "Q_table[(2, 3)]_new = 0.6020299309826558\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 2 step\n",
            "Delta Q = 0.9540950311870521\n",
            "Q_table[2,2]_old = 0.5315175561028288\n",
            "Q_table[(2, 2)]_new = 0.532460831679598\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 3 step\n",
            "Delta Q = 0.9540950311870521\n",
            "Q_table[3,2]_old = 0.5219538099209161\n",
            "Q_table[(3, 2)]_new = 0.5238534601158765\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 4 step\n",
            "Delta Q = 0.9610788355277722\n",
            "Q_table[3,0]_old = 0.601055902078356\n",
            "Q_table[(3, 0)]_new = 0.6020291473982926\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 5 step\n",
            "Delta Q = 0.9684310230580351\n",
            "Q_table[2,1]_old = 0.6786537280863567\n",
            "Q_table[(2, 1)]_new = 0.6792193783357561\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 6 step\n",
            "Delta Q = 0.9589382550638013\n",
            "Q_table[6,0]_old = 0.5754590325788993\n",
            "Q_table[(6, 0)]_new = 0.5768513843848107\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 0 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[0,3]_old = 0.603102346010828\n",
            "Q_table[(0, 3)]_new = 0.6039218554599634\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 1 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[2,0]_old = 0.5311916696354609\n",
            "Q_table[(2, 0)]_new = 0.5319876444674002\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 2 step\n",
            "Delta Q = 0.9539151417954853\n",
            "Q_table[1,3]_old = 0.5318499586091643\n",
            "Q_table[(1, 3)]_new = 0.5325801045437332\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 3 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[1,2]_old = 0.599057131060948\n",
            "Q_table[(1, 2)]_new = 0.6002811620050713\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 4 step\n",
            "Delta Q = 0.9540253045804564\n",
            "Q_table[2,0]_old = 0.5319876444674002\n",
            "Q_table[(2, 0)]_new = 0.5328141846011166\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 5 step\n",
            "Delta Q = 0.9540253045804564\n",
            "Q_table[1,3]_old = 0.5325801045437332\n",
            "Q_table[(1, 3)]_new = 0.5333473986698163\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 6 step\n",
            "Delta Q = 0.9589382550638013\n",
            "Q_table[1,1]_old = 0.5754886362432914\n",
            "Q_table[(1, 1)]_new = 0.5768780276827635\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 7 step\n",
            "Delta Q = 0.9657802978360621\n",
            "Q_table[5,1]_old = 0.6051389629293452\n",
            "Q_table[(5, 1)]_new = 0.6104053644724728\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 8 step\n",
            "Delta Q = 0.9335492760653303\n",
            "Q_table[9,0]_old = 0.2638308375249734\n",
            "Q_table[(9, 0)]_new = 0.27099702983780627\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 9 step\n",
            "Delta Q = 0.9657802978360621\n",
            "Q_table[8,2]_old = 0.3727697340592251\n",
            "Q_table[(8, 2)]_new = 0.4012730584893647\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 10 step\n",
            "Delta Q = 0.9589382550638013\n",
            "Q_table[9,3]_old = 0.48743678040439214\n",
            "Q_table[(9, 3)]_new = 0.49763135742775416\n",
            "We are on 9 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 0 step\n",
            "Delta Q = 0.9541826232658464\n",
            "Q_table[0,2]_old = 0.5280055470351496\n",
            "Q_table[(0, 2)]_new = 0.5293876155974809\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 1 step\n",
            "Delta Q = 0.9541826232658464\n",
            "Q_table[3,2]_old = 0.5238534601158765\n",
            "Q_table[(3, 2)]_new = 0.5256507373701352\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 2 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[3,0]_old = 0.6020291473982926\n",
            "Q_table[(3, 0)]_new = 0.6029559767086815\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 3 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[2,3]_old = 0.6020299309826558\n",
            "Q_table[(2, 3)]_new = 0.6029566819346083\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 4 step\n",
            "Delta Q = 0.9542660379037814\n",
            "Q_table[2,2]_old = 0.532460831679598\n",
            "Q_table[(2, 2)]_new = 0.5334807864154195\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 5 step\n",
            "Delta Q = 0.9542660379037814\n",
            "Q_table[3,3]_old = 0.5220876945578647\n",
            "Q_table[(3, 3)]_new = 0.5241449630058597\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 6 step\n",
            "Delta Q = 0.9542660379037814\n",
            "Q_table[3,2]_old = 0.5256507373701352\n",
            "Q_table[(3, 2)]_new = 0.527351701536903\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 7 step\n",
            "Delta Q = 0.9542660379037814\n",
            "Q_table[3,3]_old = 0.5241449630058597\n",
            "Q_table[(3, 3)]_new = 0.525996504609055\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 8 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[3,0]_old = 0.6029559767086815\n",
            "Q_table[(3, 0)]_new = 0.6037901230880315\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 9 step\n",
            "Delta Q = 0.9543411110779229\n",
            "Q_table[2,2]_old = 0.5334807864154195\n",
            "Q_table[(2, 2)]_new = 0.5344738188518003\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 10 step\n",
            "Delta Q = 0.9543411110779229\n",
            "Q_table[3,3]_old = 0.525996504609055\n",
            "Q_table[(3, 3)]_new = 0.5277379652260723\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 0 step\n",
            "Delta Q = 0.9540253045804564\n",
            "Q_table[0,0]_old = 0.5316520370071105\n",
            "Q_table[(0, 0)]_new = 0.5325121378868559\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 1 step\n",
            "Delta Q = 0.9589382550638013\n",
            "Q_table[1,1]_old = 0.5768780276827635\n",
            "Q_table[(1, 1)]_new = 0.5781284799782884\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 2 step\n",
            "Delta Q = 0.9684310230580351\n",
            "Q_table[5,2]_old = 0.6548695007089025\n",
            "Q_table[(5, 2)]_new = 0.6578135736960473\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 3 step\n",
            "Delta Q = 0.9592032216326443\n",
            "Q_table[6,0]_old = 0.5768513843848107\n",
            "Q_table[(6, 0)]_new = 0.5783694675789739\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 4 step\n",
            "Delta Q = 0.9540253045804564\n",
            "Q_table[5,3]_old = 0.513670911717187\n",
            "Q_table[(5, 3)]_new = 0.5163291251259248\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 5 step\n",
            "Delta Q = 0.9540253045804564\n",
            "Q_table[1,3]_old = 0.5333473986698163\n",
            "Q_table[(1, 3)]_new = 0.5340379633832911\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 6 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[1,2]_old = 0.6002811620050713\n",
            "Q_table[(1, 2)]_new = 0.6013827898547823\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 7 step\n",
            "Delta Q = 0.9611297440502181\n",
            "Q_table[2,3]_old = 0.6029566819346083\n",
            "Q_table[(2, 3)]_new = 0.6037907577913656\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 8 step\n",
            "Delta Q = 0.9684310230580351\n",
            "Q_table[2,1]_old = 0.6792193783357561\n",
            "Q_table[(2, 1)]_new = 0.6797284635602155\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 9 step\n",
            "Delta Q = 0.9771525159241524\n",
            "Q_table[6,1]_old = 0.7603447006448337\n",
            "Q_table[(6, 1)]_new = 0.7614627465045027\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 0 step\n",
            "Delta Q = 0.9543411110779229\n",
            "Q_table[0,2]_old = 0.5293876155974809\n",
            "Q_table[(0, 2)]_new = 0.5307899651156557\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 1 step\n",
            "Delta Q = 0.9543411110779229\n",
            "Q_table[3,3]_old = 0.5277379652260723\n",
            "Q_table[(3, 3)]_new = 0.529305279781388\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 0 step\n",
            "Delta Q = 0.9685316471854053\n",
            "Q_table[0,1]_old = 0.6737973008509689\n",
            "Q_table[(0, 1)]_new = 0.6749492179512773\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 0 step\n",
            "Delta Q = 0.9685316471854053\n",
            "Q_table[0,1]_old = 0.6749492179512773\n",
            "Q_table[(0, 1)]_new = 0.6759859433415548\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 1 step\n",
            "Delta Q = 0.9771525159241524\n",
            "Q_table[6,1]_old = 0.7614627465045027\n",
            "Q_table[(6, 1)]_new = 0.7624689877782049\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 2 step\n",
            "Delta Q = 0.9686222089000385\n",
            "Q_table[10,3]_old = 0.6521854428314494\n",
            "Q_table[(10, 3)]_new = 0.655589107448343\n",
            "We are on 10 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 3 step\n",
            "Delta Q = 0.9592032216326443\n",
            "Q_table[6,0]_old = 0.5783694675789739\n",
            "Q_table[(6, 0)]_new = 0.5797357424537207\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 4 step\n",
            "Delta Q = 0.9657802978360621\n",
            "Q_table[5,1]_old = 0.6104053644724728\n",
            "Q_table[(5, 1)]_new = 0.6151451258612877\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 5 step\n",
            "Delta Q = 0.9721933389997977\n",
            "Q_table[9,1]_old = 0.5738681704542209\n",
            "Q_table[(9, 1)]_new = 0.5886746924085965\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[13,0]_old = 0.0\n",
            "Q_table[(13, 0)]_new = 0.0\n",
            "We are on 13 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 0 step\n",
            "Delta Q = 0.9686222089000385\n",
            "Q_table[0,1]_old = 0.6759859433415548\n",
            "Q_table[(0, 1)]_new = 0.6770095579074378\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 1 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[6,3]_old = 0.5994038846882108\n",
            "Q_table[(6, 3)]_new = 0.6006390579398091\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 2 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[2,3]_old = 0.6037907577913656\n",
            "Q_table[(2, 3)]_new = 0.6045872437326484\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 3 step\n",
            "Delta Q = 0.9543411110779229\n",
            "Q_table[2,2]_old = 0.5344738188518003\n",
            "Q_table[(2, 2)]_new = 0.5353675480445432\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 4 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[3,0]_old = 0.6037901230880315\n",
            "Q_table[(3, 0)]_new = 0.6045866724996477\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 5 step\n",
            "Delta Q = 0.9544128005249684\n",
            "Q_table[2,2]_old = 0.5353675480445432\n",
            "Q_table[(2, 2)]_new = 0.5362435937650573\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 6 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[3,0]_old = 0.6045866724996477\n",
            "Q_table[(3, 0)]_new = 0.6053035669701023\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 7 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[2,3]_old = 0.6045872437326484\n",
            "Q_table[(2, 3)]_new = 0.6053040810798029\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 8 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[2,3]_old = 0.6053040810798029\n",
            "Q_table[(2, 3)]_new = 0.605949234692242\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 9 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[2,0]_old = 0.5328141846011166\n",
            "Q_table[(2, 0)]_new = 0.5336572172279354\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 10 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[1,3]_old = 0.5340379633832911\n",
            "Q_table[(1, 3)]_new = 0.5347586181318924\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 11 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[1,3]_old = 0.5347586181318924\n",
            "Q_table[(1, 3)]_new = 0.5354072074056335\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 12 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[1,3]_old = 0.5354072074056335\n",
            "Q_table[(1, 3)]_new = 0.5359909377520006\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 13 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[1,3]_old = 0.5359909377520006\n",
            "Q_table[(1, 3)]_new = 0.5365162950637309\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 14 step\n",
            "Delta Q = 0.9609308602116694\n",
            "Q_table[1,0]_old = 0.5947637773914876\n",
            "Q_table[(1, 0)]_new = 0.5962182598640082\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 0 step\n",
            "Delta Q = 0.9686222089000385\n",
            "Q_table[0,1]_old = 0.6770095579074378\n",
            "Q_table[(0, 1)]_new = 0.6779308110167325\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 1 step\n",
            "Delta Q = 0.9771525159241524\n",
            "Q_table[6,1]_old = 0.7624689877782049\n",
            "Q_table[(6, 1)]_new = 0.7633746049245369\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 2 step\n",
            "Delta Q = 0.9874968444950067\n",
            "Q_table[10,1]_old = 0.8572501769350263\n",
            "Q_table[(10, 1)]_new = 0.8590220037365304\n",
            "We are on 10 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 3 step\n",
            "Delta Q = 0.9874968444950067\n",
            "Q_table[14,1]_old = 0.8119127282705894\n",
            "Q_table[(14, 1)]_new = 0.8182182999385371\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 4 step\n",
            "Delta Q = 1.0\n",
            "Q_table[14,2]_old = 0.9721871610556305\n",
            "Q_table[(14, 2)]_new = 0.9749684449500675\n",
            "We are on 14 state\n",
            "And now we are on 15 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 0 step\n",
            "Delta Q = 0.9687037144432084\n",
            "Q_table[0,1]_old = 0.6779308110167325\n",
            "Q_table[(0, 1)]_new = 0.6788414443582675\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 1 step\n",
            "Delta Q = 0.9592032216326443\n",
            "Q_table[6,0]_old = 0.5797357424537207\n",
            "Q_table[(6, 0)]_new = 0.5809653898409929\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 2 step\n",
            "Delta Q = 0.9687037144432084\n",
            "Q_table[5,2]_old = 0.6578135736960473\n",
            "Q_table[(5, 2)]_new = 0.660735930769651\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 3 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7633746049245369\n",
            "Q_table[(6, 1)]_new = 0.7643491247683709\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 4 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[10,3]_old = 0.655589107448343\n",
            "Q_table[(10, 3)]_new = 0.658821617932662\n",
            "We are on 10 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 5 step\n",
            "Delta Q = 0.9594662337692687\n",
            "Q_table[6,0]_old = 0.5809653898409929\n",
            "Q_table[(6, 0)]_new = 0.5823350846261622\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 6 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[5,2]_old = 0.660735930769651\n",
            "Q_table[(5, 2)]_new = 0.6634537589218393\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 0 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[0,1]_old = 0.6788414443582675\n",
            "Q_table[(0, 1)]_new = 0.6797487211515942\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 1 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[6,3]_old = 0.6006390579398091\n",
            "Q_table[(6, 3)]_new = 0.6017507138662476\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 2 step\n",
            "Delta Q = 0.9544773210273092\n",
            "Q_table[2,2]_old = 0.5362435937650573\n",
            "Q_table[(2, 2)]_new = 0.5370965554158608\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 3 step\n",
            "Delta Q = 0.9544773210273092\n",
            "Q_table[3,3]_old = 0.529305279781388\n",
            "Q_table[(3, 3)]_new = 0.5308520728305584\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 4 step\n",
            "Delta Q = 0.9544773210273092\n",
            "Q_table[3,2]_old = 0.527351701536903\n",
            "Q_table[(3, 2)]_new = 0.529093852410522\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 5 step\n",
            "Delta Q = 0.9544773210273092\n",
            "Q_table[3,2]_old = 0.529093852410522\n",
            "Q_table[(3, 2)]_new = 0.530661788196779\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 6 step\n",
            "Delta Q = 0.9544773210273092\n",
            "Q_table[3,2]_old = 0.530661788196779\n",
            "Q_table[(3, 2)]_new = 0.5320729304044103\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 7 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[3,0]_old = 0.6053035669701023\n",
            "Q_table[(3, 0)]_new = 0.6059487719935115\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 8 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[2,0]_old = 0.5336572172279354\n",
            "Q_table[(2, 0)]_new = 0.5344159465920723\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 9 step\n",
            "Delta Q = 0.9611773849036435\n",
            "Q_table[1,0]_old = 0.5962182598640082\n",
            "Q_table[(1, 0)]_new = 0.5977738187812509\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 0 step\n",
            "Delta Q = 0.9541244510869304\n",
            "Q_table[0,0]_old = 0.5325121378868559\n",
            "Q_table[(0, 0)]_new = 0.5333853751851008\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 1 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[1,2]_old = 0.6013827898547823\n",
            "Q_table[(1, 2)]_new = 0.6024200725897235\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 2 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[2,0]_old = 0.5344159465920723\n",
            "Q_table[(2, 0)]_new = 0.5351921584659401\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 3 step\n",
            "Delta Q = 0.9597108383029656\n",
            "Q_table[1,1]_old = 0.5781284799782884\n",
            "Q_table[(1, 1)]_new = 0.5800264702834251\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 0 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[0,3]_old = 0.6039218554599634\n",
            "Q_table[(0, 3)]_new = 0.6047052316343864\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 1 step\n",
            "Delta Q = 0.9545353894794161\n",
            "Q_table[2,2]_old = 0.5370965554158608\n",
            "Q_table[(2, 2)]_new = 0.5379222893536907\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 2 step\n",
            "Delta Q = 0.9545353894794161\n",
            "Q_table[3,3]_old = 0.5308520728305584\n",
            "Q_table[(3, 3)]_new = 0.5323022550269185\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 3 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[3,0]_old = 0.6059487719935115\n",
            "Q_table[(3, 0)]_new = 0.6065294565145798\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 4 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[2,3]_old = 0.605949234692242\n",
            "Q_table[(2, 3)]_new = 0.6065298729434372\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 5 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[2,2]_old = 0.5379222893536907\n",
            "Q_table[(2, 2)]_new = 0.5387177115046338\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 6 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,2]_old = 0.5320729304044103\n",
            "Q_table[(3, 2)]_new = 0.5334532884502814\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 7 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,3]_old = 0.5323022550269185\n",
            "Q_table[(3, 3)]_new = 0.5336596806105388\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 8 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,2]_old = 0.5334532884502814\n",
            "Q_table[(3, 2)]_new = 0.5346956106915655\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 9 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,3]_old = 0.5336596806105388\n",
            "Q_table[(3, 3)]_new = 0.5348813636357971\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 0 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[0,0]_old = 0.5333853751851008\n",
            "Q_table[(0, 0)]_new = 0.5342646441996658\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 1 step\n",
            "Delta Q = 0.9611773849036435\n",
            "Q_table[1,0]_old = 0.5977738187812509\n",
            "Q_table[(1, 0)]_new = 0.5991738218067693\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 0 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[0,0]_old = 0.5342646441996658\n",
            "Q_table[(0, 0)]_new = 0.5350559863127744\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 1 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[1,3]_old = 0.5365162950637309\n",
            "Q_table[(1, 3)]_new = 0.5370824720904329\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 2 step\n",
            "Delta Q = 0.9611773849036435\n",
            "Q_table[1,0]_old = 0.5991738218067693\n",
            "Q_table[(1, 0)]_new = 0.6004338245297358\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 0 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[0,1]_old = 0.6797487211515942\n",
            "Q_table[(0, 1)]_new = 0.6805652702655882\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 1 step\n",
            "Delta Q = 0.9597108383029656\n",
            "Q_table[6,0]_old = 0.5823350846261622\n",
            "Q_table[(6, 0)]_new = 0.5838124144665116\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 2 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[5,3]_old = 0.5163291251259248\n",
            "Q_table[(5, 3)]_new = 0.5189140191464074\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 3 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[1,3]_old = 0.5370824720904329\n",
            "Q_table[(1, 3)]_new = 0.5375920314144648\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 4 step\n",
            "Delta Q = 0.9597108383029656\n",
            "Q_table[1,1]_old = 0.5800264702834251\n",
            "Q_table[(1, 1)]_new = 0.5817346615580482\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 5 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[5,2]_old = 0.6634537589218393\n",
            "Q_table[(5, 2)]_new = 0.6658998042588088\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 0 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[0,2]_old = 0.5307899651156557\n",
            "Q_table[(0, 2)]_new = 0.5322986196904023\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 0 step\n",
            "Delta Q = 0.9542178065330751\n",
            "Q_table[0,0]_old = 0.5350559863127744\n",
            "Q_table[(0, 0)]_new = 0.5357681942145721\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 1 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[1,2]_old = 0.6024200725897235\n",
            "Q_table[(1, 2)]_new = 0.6033536270511706\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 2 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[2,2]_old = 0.5387177115046338\n",
            "Q_table[(2, 2)]_new = 0.5394335914404825\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 3 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,3]_old = 0.5348813636357971\n",
            "Q_table[(3, 3)]_new = 0.5359808783585296\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 0 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[0,2]_old = 0.5322986196904023\n",
            "Q_table[(0, 2)]_new = 0.5336564088076742\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 1 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,2]_old = 0.5346956106915655\n",
            "Q_table[(3, 2)]_new = 0.5358137007087211\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 2 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[3,2]_old = 0.5358137007087211\n",
            "Q_table[(3, 2)]_new = 0.5368199817241612\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 0 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[0,0]_old = 0.5357681942145721\n",
            "Q_table[(0, 0)]_new = 0.5364932012277203\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 1 step\n",
            "Delta Q = 0.961250874323903\n",
            "Q_table[1,0]_old = 0.6004338245297358\n",
            "Q_table[(1, 0)]_new = 0.6016413164006652\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 0 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[0,3]_old = 0.6047052316343864\n",
            "Q_table[(0, 3)]_new = 0.6054102701913672\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 1 step\n",
            "Delta Q = 0.9611755617204194\n",
            "Q_table[2,3]_old = 0.6065298729434372\n",
            "Q_table[(2, 3)]_new = 0.6070524473695129\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 2 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[2,1]_old = 0.6797284635602155\n",
            "Q_table[(2, 1)]_new = 0.6805470384333474\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 0 step\n",
            "Delta Q = 0.9612492334590013\n",
            "Q_table[0,3]_old = 0.6054102701913672\n",
            "Q_table[(0, 3)]_new = 0.6061184766312318\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 1 step\n",
            "Delta Q = 0.9545876510863122\n",
            "Q_table[2,2]_old = 0.5394335914404825\n",
            "Q_table[(2, 2)]_new = 0.5400778833827464\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 2 step\n",
            "Delta Q = 0.9612492334590013\n",
            "Q_table[3,0]_old = 0.6065294565145798\n",
            "Q_table[(3, 0)]_new = 0.6071257443221231\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 3 step\n",
            "Delta Q = 0.9687914212291534\n",
            "Q_table[2,1]_old = 0.6805470384333474\n",
            "Q_table[(2, 1)]_new = 0.6812837558191661\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 4 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7643491247683709\n",
            "Q_table[(6, 1)]_new = 0.7652261926278215\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 5 step\n",
            "Delta Q = 0.9657802978360621\n",
            "Q_table[10,0]_old = 0.585139793389986\n",
            "Q_table[(10, 0)]_new = 0.5924061118870495\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 6 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[9,2]_old = 0.7308921981784677\n",
            "Q_table[(9, 2)]_new = 0.7351149586969087\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 0 step\n",
            "Delta Q = 0.9546413169889911\n",
            "Q_table[0,2]_old = 0.5336564088076742\n",
            "Q_table[(0, 2)]_new = 0.5349320849158978\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 1 step\n",
            "Delta Q = 0.9613155380237249\n",
            "Q_table[3,0]_old = 0.6071257443221231\n",
            "Q_table[(3, 0)]_new = 0.6077287079136356\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 2 step\n",
            "Delta Q = 0.9613155380237249\n",
            "Q_table[2,3]_old = 0.6070524473695129\n",
            "Q_table[(2, 3)]_new = 0.6076627406562866\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 3 step\n",
            "Delta Q = 0.9613155380237249\n",
            "Q_table[2,3]_old = 0.6076627406562866\n",
            "Q_table[(2, 3)]_new = 0.6082120046143829\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 4 step\n",
            "Delta Q = 0.968870357336504\n",
            "Q_table[2,1]_old = 0.6812837558191661\n",
            "Q_table[(2, 1)]_new = 0.6820257375737534\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 5 step\n",
            "Delta Q = 0.9599309823832928\n",
            "Q_table[6,0]_old = 0.5838124144665116\n",
            "Q_table[(6, 0)]_new = 0.5853621554031532\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 6 step\n",
            "Delta Q = 0.968870357336504\n",
            "Q_table[5,2]_old = 0.6658998042588088\n",
            "Q_table[(5, 2)]_new = 0.6681801811694319\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 7 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7652261926278215\n",
            "Q_table[(6, 1)]_new = 0.7660155537013271\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 8 step\n",
            "Delta Q = 0.9661603462827218\n",
            "Q_table[10,0]_old = 0.5924061118870495\n",
            "Q_table[(10, 0)]_new = 0.5993258469810664\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 9 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[9,2]_old = 0.7351149586969087\n",
            "Q_table[(9, 2)]_new = 0.7389154431635055\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 10 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[10,3]_old = 0.658821617932662\n",
            "Q_table[(10, 3)]_new = 0.6618808559725152\n",
            "We are on 10 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 11 step\n",
            "Delta Q = 0.9613823163816378\n",
            "Q_table[6,3]_old = 0.6017507138662476\n",
            "Q_table[(6, 3)]_new = 0.6029579588612607\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 12 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[2,0]_old = 0.5351921584659401\n",
            "Q_table[(2, 0)]_new = 0.5359747690539515\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 13 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[1,3]_old = 0.5375920314144648\n",
            "Q_table[(1, 3)]_new = 0.5381346547076237\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 14 step\n",
            "Delta Q = 0.961250874323903\n",
            "Q_table[1,0]_old = 0.6016413164006652\n",
            "Q_table[(1, 0)]_new = 0.6027280590845017\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 0 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[0,1]_old = 0.6805652702655882\n",
            "Q_table[(0, 1)]_new = 0.6814501430721488\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 0 step\n",
            "Delta Q = 0.9613823163816378\n",
            "Q_table[0,3]_old = 0.6061184766312318\n",
            "Q_table[(0, 3)]_new = 0.6068889453497465\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 1 step\n",
            "Delta Q = 0.9613823163816378\n",
            "Q_table[2,3]_old = 0.6082120046143829\n",
            "Q_table[(2, 3)]_new = 0.6087731205345824\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 2 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[2,2]_old = 0.5400778833827464\n",
            "Q_table[(2, 2)]_new = 0.540765678756699\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 3 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[3,3]_old = 0.5359808783585296\n",
            "Q_table[(3, 3)]_new = 0.5370783742349039\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 0 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[0,2]_old = 0.5349320849158978\n",
            "Q_table[(0, 2)]_new = 0.5361344601365352\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 1 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[3,2]_old = 0.5368199817241612\n",
            "Q_table[(3, 2)]_new = 0.5378335672639724\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 0 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[0,2]_old = 0.5361344601365352\n",
            "Q_table[(0, 2)]_new = 0.5372165978351089\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 0 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[0,2]_old = 0.5372165978351089\n",
            "Q_table[(0, 2)]_new = 0.5381905217638252\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 1 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[3,2]_old = 0.5378335672639724\n",
            "Q_table[(3, 2)]_new = 0.5387457942498024\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 0 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[0,1]_old = 0.6814501430721488\n",
            "Q_table[(0, 1)]_new = 0.6822465285980533\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 0 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[0,0]_old = 0.5364932012277203\n",
            "Q_table[(0, 0)]_new = 0.5371457075395536\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 1 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[1,3]_old = 0.5381346547076237\n",
            "Q_table[(1, 3)]_new = 0.5386230156714666\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 2 step\n",
            "Delta Q = 0.9601362163052489\n",
            "Q_table[1,1]_old = 0.5817346615580482\n",
            "Q_table[(1, 1)]_new = 0.5836974117074923\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 3 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[5,2]_old = 0.6681801811694319\n",
            "Q_table[(5, 2)]_new = 0.6703035628856081\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 0 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[0,1]_old = 0.6822465285980533\n",
            "Q_table[(0, 1)]_new = 0.6829632755713675\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 0 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[0,0]_old = 0.5371457075395536\n",
            "Q_table[(0, 0)]_new = 0.5377329632202036\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 1 step\n",
            "Delta Q = 0.9603273206597047\n",
            "Q_table[1,1]_old = 0.5836974117074923\n",
            "Q_table[(1, 1)]_new = 0.5856549911964478\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 2 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[5,3]_old = 0.5189140191464074\n",
            "Q_table[(5, 3)]_new = 0.521324443666372\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 3 step\n",
            "Delta Q = 0.9543018264346054\n",
            "Q_table[1,3]_old = 0.5386230156714666\n",
            "Q_table[(1, 3)]_new = 0.5390625405389253\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 4 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.6027280590845017\n",
            "Q_table[(1, 0)]_new = 0.6039219479774746\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 0 step\n",
            "Delta Q = 0.9613823163816378\n",
            "Q_table[0,3]_old = 0.6068889453497465\n",
            "Q_table[(0, 3)]_new = 0.6075823671964097\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 1 step\n",
            "Delta Q = 0.9543529753179727\n",
            "Q_table[2,0]_old = 0.5359747690539515\n",
            "Q_table[(2, 0)]_new = 0.5367302674665291\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 2 step\n",
            "Delta Q = 0.9613823163816378\n",
            "Q_table[1,2]_old = 0.6033536270511706\n",
            "Q_table[(1, 2)]_new = 0.6044005807276913\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 3 step\n",
            "Delta Q = 0.9543960522654923\n",
            "Q_table[2,0]_old = 0.5367302674665291\n",
            "Q_table[(2, 0)]_new = 0.5374532929853684\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 4 step\n",
            "Delta Q = 0.9613823163816378\n",
            "Q_table[1,2]_old = 0.6044005807276913\n",
            "Q_table[(1, 2)]_new = 0.60534283903656\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 5 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[2,1]_old = 0.6820257375737534\n",
            "Q_table[(2, 1)]_new = 0.6827645636494974\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 0 step\n",
            "Delta Q = 0.9614488107284548\n",
            "Q_table[0,3]_old = 0.6075823671964097\n",
            "Q_table[(0, 3)]_new = 0.6082729412052235\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 1 step\n",
            "Delta Q = 0.9614488107284548\n",
            "Q_table[2,3]_old = 0.6087731205345824\n",
            "Q_table[(2, 3)]_new = 0.6093446192095789\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 2 step\n",
            "Delta Q = 0.9544808555132904\n",
            "Q_table[2,0]_old = 0.5374532929853684\n",
            "Q_table[(2, 0)]_new = 0.538188819200122\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 3 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.6039219479774746\n",
            "Q_table[(1, 0)]_new = 0.6049964479811502\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 0 step\n",
            "Delta Q = 0.9544808555132904\n",
            "Q_table[0,0]_old = 0.5377329632202036\n",
            "Q_table[(0, 0)]_new = 0.5384405224114737\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 1 step\n",
            "Delta Q = 0.9603273206597047\n",
            "Q_table[1,1]_old = 0.5856549911964478\n",
            "Q_table[(1, 1)]_new = 0.5874168127365077\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 2 step\n",
            "Delta Q = 0.9689413998331194\n",
            "Q_table[5,2]_old = 0.6703035628856081\n",
            "Q_table[(5, 2)]_new = 0.6722146064301667\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 3 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7660155537013271\n",
            "Q_table[(6, 1)]_new = 0.7667259786674822\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 4 step\n",
            "Delta Q = 0.9665023898847155\n",
            "Q_table[10,0]_old = 0.5993258469810664\n",
            "Q_table[(10, 0)]_new = 0.6058956521676753\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 5 step\n",
            "Delta Q = 0.9361145752640428\n",
            "Q_table[9,0]_old = 0.27099702983780627\n",
            "Q_table[(9, 0)]_new = 0.2800119021180685\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 6 step\n",
            "Delta Q = 0.9361145752640428\n",
            "Q_table[8,0]_old = 0.14000671622570926\n",
            "Q_table[(8, 0)]_new = 0.16212061986718115\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 7 step\n",
            "Delta Q = 0.9665023898847155\n",
            "Q_table[8,2]_old = 0.4012730584893647\n",
            "Q_table[(8, 2)]_new = 0.4276481425251437\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 8 step\n",
            "Delta Q = 0.938488332827263\n",
            "Q_table[9,0]_old = 0.2800119021180685\n",
            "Q_table[(9, 0)]_new = 0.29049904473352456\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 0 step\n",
            "Delta Q = 0.9614488107284548\n",
            "Q_table[0,3]_old = 0.6082729412052235\n",
            "Q_table[(0, 3)]_new = 0.6088944578131559\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 1 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[2,2]_old = 0.540765678756699\n",
            "Q_table[(2, 2)]_new = 0.5413846945932563\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 2 step\n",
            "Delta Q = 0.9546955837122273\n",
            "Q_table[3,3]_old = 0.5370783742349039\n",
            "Q_table[(3, 3)]_new = 0.5380661205236408\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 3 step\n",
            "Delta Q = 0.9614488107284548\n",
            "Q_table[3,0]_old = 0.6077287079136356\n",
            "Q_table[(3, 0)]_new = 0.6084046478507269\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 4 step\n",
            "Delta Q = 0.9690053380800734\n",
            "Q_table[2,1]_old = 0.6827645636494974\n",
            "Q_table[(2, 1)]_new = 0.6834934453646211\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 5 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7667259786674822\n",
            "Q_table[(6, 1)]_new = 0.7673653611370217\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 0 step\n",
            "Delta Q = 0.9547564183065654\n",
            "Q_table[0,2]_old = 0.5381905217638252\n",
            "Q_table[(0, 2)]_new = 0.5391278878940081\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 1 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[3,0]_old = 0.6084046478507269\n",
            "Q_table[(3, 0)]_new = 0.6090785931484701\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 2 step\n",
            "Delta Q = 0.9544808555132904\n",
            "Q_table[2,0]_old = 0.538188819200122\n",
            "Q_table[(2, 0)]_new = 0.5388507927934002\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 3 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[1,1]_old = 0.5874168127365077\n",
            "Q_table[(1, 1)]_new = 0.589174446041572\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 4 step\n",
            "Delta Q = 0.9544808555132904\n",
            "Q_table[5,3]_old = 0.521324443666372\n",
            "Q_table[(5, 3)]_new = 0.5236728548130252\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 5 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.6049964479811502\n",
            "Q_table[(1, 0)]_new = 0.6059634979844583\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 0 step\n",
            "Delta Q = 0.9545367148186013\n",
            "Q_table[0,0]_old = 0.5384405224114737\n",
            "Q_table[(0, 0)]_new = 0.5391331849889276\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 1 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[1,2]_old = 0.60534283903656\n",
            "Q_table[(1, 2)]_new = 0.6063229652157199\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 2 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[2,3]_old = 0.6093446192095789\n",
            "Q_table[(2, 3)]_new = 0.609924567371437\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 3 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[2,3]_old = 0.609924567371437\n",
            "Q_table[(2, 3)]_new = 0.6104465207171091\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 4 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[2,2]_old = 0.5413846945932563\n",
            "Q_table[(2, 2)]_new = 0.5420632985172931\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 5 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[3,3]_old = 0.5380661205236408\n",
            "Q_table[(3, 3)]_new = 0.539076581854639\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 6 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[3,2]_old = 0.5387457942498024\n",
            "Q_table[(3, 2)]_new = 0.5396882882081845\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 0 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[0,3]_old = 0.6088944578131559\n",
            "Q_table[(0, 3)]_new = 0.6095194221146562\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 1 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[2,2]_old = 0.5420632985172931\n",
            "Q_table[(2, 2)]_new = 0.5426740420489261\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 0 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[0,3]_old = 0.6095194221146562\n",
            "Q_table[(0, 3)]_new = 0.6100818899860064\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 1 step\n",
            "Delta Q = 0.9545690668694148\n",
            "Q_table[2,0]_old = 0.5388507927934002\n",
            "Q_table[(2, 0)]_new = 0.539534780383475\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 2 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.6059634979844583\n",
            "Q_table[(1, 0)]_new = 0.6068338429874355\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 0 step\n",
            "Delta Q = 0.9546150458688692\n",
            "Q_table[0,0]_old = 0.5391331849889276\n",
            "Q_table[(0, 0)]_new = 0.539834912358904\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 1 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[1,1]_old = 0.589174446041572\n",
            "Q_table[(1, 1)]_new = 0.5907563160161299\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 2 step\n",
            "Delta Q = 0.9546150458688692\n",
            "Q_table[5,3]_old = 0.5236728548130252\n",
            "Q_table[(5, 3)]_new = 0.5259206152005919\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 3 step\n",
            "Delta Q = 0.9546150458688692\n",
            "Q_table[1,3]_old = 0.5390625405389253\n",
            "Q_table[(1, 3)]_new = 0.539771332353902\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 4 step\n",
            "Delta Q = 0.9546150458688692\n",
            "Q_table[1,3]_old = 0.539771332353902\n",
            "Q_table[(1, 3)]_new = 0.540409244987381\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 5 step\n",
            "Delta Q = 0.9615144100828159\n",
            "Q_table[1,2]_old = 0.6063229652157199\n",
            "Q_table[(1, 2)]_new = 0.6072050787769638\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 6 step\n",
            "Delta Q = 0.969062882502332\n",
            "Q_table[2,1]_old = 0.6834934453646211\n",
            "Q_table[(2, 1)]_new = 0.6842069833304909\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 0 step\n",
            "Delta Q = 0.9546484570899267\n",
            "Q_table[0,0]_old = 0.539834912358904\n",
            "Q_table[(0, 0)]_new = 0.5404998782129403\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 1 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.6068338429874355\n",
            "Q_table[(1, 0)]_new = 0.607617153490115\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 0 step\n",
            "Delta Q = 0.9546855438141104\n",
            "Q_table[0,0]_old = 0.5404998782129403\n",
            "Q_table[(0, 0)]_new = 0.5411354342057567\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 1 step\n",
            "Delta Q = 0.9615786284997442\n",
            "Q_table[1,2]_old = 0.6072050787769638\n",
            "Q_table[(1, 2)]_new = 0.6080631993990117\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 2 step\n",
            "Delta Q = 0.969062882502332\n",
            "Q_table[2,1]_old = 0.6842069833304909\n",
            "Q_table[(2, 1)]_new = 0.6848491674997738\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 3 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[6,0]_old = 0.5853621554031532\n",
            "Q_table[(6, 0)]_new = 0.5873252544415529\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 4 step\n",
            "Delta Q = 0.9547256879459111\n",
            "Q_table[5,3]_old = 0.5259206152005919\n",
            "Q_table[(5, 3)]_new = 0.5280542416264438\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 5 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.607617153490115\n",
            "Q_table[(1, 0)]_new = 0.6083221329425266\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 0 step\n",
            "Delta Q = 0.9616364250749797\n",
            "Q_table[0,3]_old = 0.6100818899860064\n",
            "Q_table[(0, 3)]_new = 0.6107101260623855\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 1 step\n",
            "Delta Q = 0.969062882502332\n",
            "Q_table[2,1]_old = 0.6848491674997738\n",
            "Q_table[(2, 1)]_new = 0.6854271332521283\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 2 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[6,0]_old = 0.5873252544415529\n",
            "Q_table[(6, 0)]_new = 0.5890920435761127\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 3 step\n",
            "Delta Q = 0.9547489919648274\n",
            "Q_table[5,3]_old = 0.5280542416264438\n",
            "Q_table[(5, 3)]_new = 0.5299978094286267\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 4 step\n",
            "Delta Q = 0.9614666948014231\n",
            "Q_table[1,0]_old = 0.6083221329425266\n",
            "Q_table[(1, 0)]_new = 0.6089566144496971\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 0 step\n",
            "Delta Q = 0.9616884419926915\n",
            "Q_table[0,3]_old = 0.6107101260623855\n",
            "Q_table[(0, 3)]_new = 0.6113275554488385\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 1 step\n",
            "Delta Q = 0.969062882502332\n",
            "Q_table[2,1]_old = 0.6854271332521283\n",
            "Q_table[(2, 1)]_new = 0.6859473024292475\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 2 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7673653611370217\n",
            "Q_table[(6, 1)]_new = 0.7679408053596073\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 3 step\n",
            "Delta Q = 0.9665023898847155\n",
            "Q_table[10,0]_old = 0.6058956521676753\n",
            "Q_table[(10, 0)]_new = 0.6118084768356232\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 4 step\n",
            "Delta Q = 0.9721933389997977\n",
            "Q_table[9,1]_old = 0.5886746924085965\n",
            "Q_table[(9, 1)]_new = 0.6020005621675345\n",
            "We are on 9 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 5 step\n",
            "Delta Q = 0.9877471600455061\n",
            "Q_table[13,2]_old = 0.8021482111088624\n",
            "Q_table[(13, 2)]_new = 0.8096805500434823\n",
            "We are on 13 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 6 step\n",
            "Delta Q = 1.0\n",
            "Q_table[14,2]_old = 0.9749684449500675\n",
            "Q_table[(14, 2)]_new = 0.9774716004550608\n",
            "We are on 14 state\n",
            "And now we are on 15 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 0 step\n",
            "Delta Q = 0.9691146724823647\n",
            "Q_table[0,1]_old = 0.6829632755713675\n",
            "Q_table[(0, 1)]_new = 0.6837816204965954\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 1 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[6,1]_old = 0.7679408053596073\n",
            "Q_table[(6, 1)]_new = 0.7684587051599343\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 0 step\n",
            "Delta Q = 0.9617352572186323\n",
            "Q_table[0,3]_old = 0.6113275554488385\n",
            "Q_table[(0, 3)]_new = 0.611930057122587\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 1 step\n",
            "Delta Q = 0.9548060953004728\n",
            "Q_table[2,0]_old = 0.539534780383475\n",
            "Q_table[(2, 0)]_new = 0.5403873976456003\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 2 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[1,1]_old = 0.5907563160161299\n",
            "Q_table[(1, 1)]_new = 0.5921799989932319\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 3 step\n",
            "Delta Q = 0.9665023898847155\n",
            "Q_table[5,1]_old = 0.6151451258612877\n",
            "Q_table[(5, 1)]_new = 0.6201330031598744\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 4 step\n",
            "Delta Q = 0.9773119803362877\n",
            "Q_table[9,2]_old = 0.7389154431635055\n",
            "Q_table[(9, 2)]_new = 0.7423358791834427\n",
            "We are on 9 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 5 step\n",
            "Delta Q = 0.9879724440409555\n",
            "Q_table[10,1]_old = 0.8590220037365304\n",
            "Q_table[(10, 1)]_new = 0.8610922474038328\n",
            "We are on 10 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 6 step\n",
            "Delta Q = 1.0\n",
            "Q_table[14,2]_old = 0.9774716004550608\n",
            "Q_table[(14, 2)]_new = 0.9797244404095546\n",
            "We are on 14 state\n",
            "And now we are on 15 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 0 step\n",
            "Delta Q = 0.9548060953004728\n",
            "Q_table[0,0]_old = 0.5411354342057567\n",
            "Q_table[(0, 0)]_new = 0.5418279860856537\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 1 step\n",
            "Delta Q = 0.9615403458446936\n",
            "Q_table[1,0]_old = 0.6089566144496971\n",
            "Q_table[(1, 0)]_new = 0.6096012988494209\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 0 step\n",
            "Delta Q = 0.9548641168964479\n",
            "Q_table[0,0]_old = 0.5418279860856537\n",
            "Q_table[(0, 0)]_new = 0.5425093043735363\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 1 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[1,1]_old = 0.5921799989932319\n",
            "Q_table[(1, 1)]_new = 0.5934613136726238\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 0 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[0,1]_old = 0.6837816204965954\n",
            "Q_table[(0, 1)]_new = 0.68456474191133\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 1 step\n",
            "Delta Q = 0.9617352572186323\n",
            "Q_table[6,3]_old = 0.6029579588612607\n",
            "Q_table[(6, 3)]_new = 0.6043974201937669\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 2 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[2,1]_old = 0.6859473024292475\n",
            "Q_table[(2, 1)]_new = 0.6865138556507169\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 3 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[6,0]_old = 0.5890920435761127\n",
            "Q_table[(6, 0)]_new = 0.5906821537972164\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,0]_old = 0.0\n",
            "Q_table[(5, 0)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 0 step\n",
            "Delta Q = 0.9548641168964479\n",
            "Q_table[0,0]_old = 0.5425093043735363\n",
            "Q_table[(0, 0)]_new = 0.5431224908326305\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 1 step\n",
            "Delta Q = 0.9616108267720197\n",
            "Q_table[1,0]_old = 0.6096012988494209\n",
            "Q_table[(1, 0)]_new = 0.6102519957364986\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 0 step\n",
            "Delta Q = 0.9617862470085645\n",
            "Q_table[0,3]_old = 0.611930057122587\n",
            "Q_table[(0, 3)]_new = 0.6125232984188927\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 1 step\n",
            "Delta Q = 0.9617862470085645\n",
            "Q_table[2,3]_old = 0.6104465207171091\n",
            "Q_table[(2, 3)]_new = 0.6111881156539627\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 2 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[2,2]_old = 0.5426740420489261\n",
            "Q_table[(2, 2)]_new = 0.5432237112273958\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 0 step\n",
            "Delta Q = 0.9617862470085645\n",
            "Q_table[0,3]_old = 0.6125232984188927\n",
            "Q_table[(0, 3)]_new = 0.613057215585568\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 1 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[2,1]_old = 0.6865138556507169\n",
            "Q_table[(2, 1)]_new = 0.6870237535500393\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 2 step\n",
            "Delta Q = 0.9604993145787151\n",
            "Q_table[6,0]_old = 0.5906821537972164\n",
            "Q_table[(6, 0)]_new = 0.5921132529962099\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 3 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[5,2]_old = 0.6722146064301667\n",
            "Q_table[(5, 2)]_new = 0.6741544292515441\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 0 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[0,2]_old = 0.5391278878940081\n",
            "Q_table[(0, 2)]_new = 0.5400321724879696\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 0 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[0,1]_old = 0.68456474191133\n",
            "Q_table[(0, 1)]_new = 0.6852695511845911\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 1 step\n",
            "Delta Q = 0.9618321378195036\n",
            "Q_table[6,3]_old = 0.6043974201937669\n",
            "Q_table[(6, 3)]_new = 0.6057898159938938\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 2 step\n",
            "Delta Q = 0.9618321378195036\n",
            "Q_table[2,3]_old = 0.6111881156539627\n",
            "Q_table[(2, 3)]_new = 0.61190144190807\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 3 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[2,2]_old = 0.5432237112273958\n",
            "Q_table[(2, 2)]_new = 0.5437184134880185\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 0 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[0,1]_old = 0.6852695511845911\n",
            "Q_table[(0, 1)]_new = 0.6859038795305261\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 1 step\n",
            "Delta Q = 0.960673898632639\n",
            "Q_table[6,0]_old = 0.5921132529962099\n",
            "Q_table[(6, 0)]_new = 0.5935758263292279\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 2 step\n",
            "Delta Q = 0.9668102291265098\n",
            "Q_table[5,1]_old = 0.6201330031598744\n",
            "Q_table[(5, 1)]_new = 0.6249299319703968\n",
            "We are on 5 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 3 step\n",
            "Delta Q = 0.938488332827263\n",
            "Q_table[9,0]_old = 0.29049904473352456\n",
            "Q_table[(9, 0)]_new = 0.29993747308743507\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 0 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[0,0]_old = 0.5431224908326305\n",
            "Q_table[(0, 0)]_new = 0.5437329213656523\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 1 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[1,3]_old = 0.540409244987381\n",
            "Q_table[(1, 3)]_new = 0.5412910001049277\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 2 step\n",
            "Delta Q = 0.960673898632639\n",
            "Q_table[1,1]_old = 0.5934613136726238\n",
            "Q_table[(1, 1)]_new = 0.5947890809380003\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 3 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[5,2]_old = 0.6741544292515441\n",
            "Q_table[(5, 2)]_new = 0.6759002697907838\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 0 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[0,0]_old = 0.5437329213656523\n",
            "Q_table[(0, 0)]_new = 0.544282308845372\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 1 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[1,3]_old = 0.5412910001049277\n",
            "Q_table[(1, 3)]_new = 0.5420845797107198\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 2 step\n",
            "Delta Q = 0.9608310242811706\n",
            "Q_table[1,1]_old = 0.5947890809380003\n",
            "Q_table[(1, 1)]_new = 0.596141197125371\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 3 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[5,3]_old = 0.5299978094286267\n",
            "Q_table[(5, 3)]_new = 0.531920708102049\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 4 step\n",
            "Delta Q = 0.9608310242811706\n",
            "Q_table[1,1]_old = 0.596141197125371\n",
            "Q_table[(1, 1)]_new = 0.5973581016940044\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 5 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[5,3]_old = 0.531920708102049\n",
            "Q_table[(5, 3)]_new = 0.533651316908129\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 6 step\n",
            "Delta Q = 0.9608310242811706\n",
            "Q_table[1,1]_old = 0.5973581016940044\n",
            "Q_table[(1, 1)]_new = 0.5984533158057745\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 7 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[5,3]_old = 0.533651316908129\n",
            "Q_table[(5, 3)]_new = 0.535208864833601\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 8 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[1,3]_old = 0.5420845797107198\n",
            "Q_table[(1, 3)]_new = 0.5427988013559326\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 9 step\n",
            "Delta Q = 0.9618321378195036\n",
            "Q_table[1,2]_old = 0.6080631993990117\n",
            "Q_table[(1, 2)]_new = 0.6090890172786141\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 10 step\n",
            "Delta Q = 0.9618321378195036\n",
            "Q_table[2,3]_old = 0.61190144190807\n",
            "Q_table[(2, 3)]_new = 0.6125434355367666\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 11 step\n",
            "Delta Q = 0.9618321378195036\n",
            "Q_table[2,3]_old = 0.6125434355367666\n",
            "Q_table[(2, 3)]_new = 0.6131212298025935\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 12 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[2,2]_old = 0.5437184134880185\n",
            "Q_table[(2, 2)]_new = 0.544163645522579\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 13 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[3,3]_old = 0.539076581854639\n",
            "Q_table[(3, 3)]_new = 0.5399859970525375\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 14 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[3,2]_old = 0.5396882882081845\n",
            "Q_table[(3, 2)]_new = 0.5405365327707283\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 15 step\n",
            "Delta Q = 0.9548170733833623\n",
            "Q_table[3,3]_old = 0.5399859970525375\n",
            "Q_table[(3, 3)]_new = 0.5408044707306461\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 16 step\n",
            "Delta Q = 0.9618321378195036\n",
            "Q_table[3,0]_old = 0.6090785931484701\n",
            "Q_table[(3, 0)]_new = 0.6100028716531267\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 17 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[2,1]_old = 0.6870237535500393\n",
            "Q_table[(2, 1)]_new = 0.6874826616594295\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 18 step\n",
            "Delta Q = 0.9618734395493487\n",
            "Q_table[6,3]_old = 0.6057898159938938\n",
            "Q_table[(6, 3)]_new = 0.6070842739438531\n",
            "We are on 6 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 19 step\n",
            "Delta Q = 0.9549002584487815\n",
            "Q_table[2,2]_old = 0.544163645522579\n",
            "Q_table[(2, 2)]_new = 0.5446475394191025\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 20 step\n",
            "Delta Q = 0.9549002584487815\n",
            "Q_table[3,3]_old = 0.5408044707306461\n",
            "Q_table[(3, 3)]_new = 0.5416242821063629\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 21 step\n",
            "Delta Q = 0.9618734395493487\n",
            "Q_table[3,0]_old = 0.6100028716531267\n",
            "Q_table[(3, 0)]_new = 0.6108760240371627\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 22 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[2,1]_old = 0.6874826616594295\n",
            "Q_table[(2, 1)]_new = 0.6878956789578806\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 23 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 0 step\n",
            "Delta Q = 0.9619106111062092\n",
            "Q_table[0,3]_old = 0.613057215585568\n",
            "Q_table[(0, 3)]_new = 0.6136621051332205\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 1 step\n",
            "Delta Q = 0.9691612834643941\n",
            "Q_table[2,1]_old = 0.6878956789578806\n",
            "Q_table[(2, 1)]_new = 0.6882673945264867\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 2 step\n",
            "Delta Q = 0.977498302266345\n",
            "Q_table[6,1]_old = 0.7684587051599343\n",
            "Q_table[(6, 1)]_new = 0.7691111369102859\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 0 step\n",
            "Delta Q = 0.9619440655073839\n",
            "Q_table[0,3]_old = 0.6136621051332205\n",
            "Q_table[(0, 3)]_new = 0.6142399601272823\n",
            "We are on 0 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 1 step\n",
            "Delta Q = 0.9692200023219257\n",
            "Q_table[2,1]_old = 0.6882673945264867\n",
            "Q_table[(2, 1)]_new = 0.6886606573957638\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 0 step\n",
            "Delta Q = 0.9549788421633447\n",
            "Q_table[0,2]_old = 0.5400321724879696\n",
            "Q_table[(0, 2)]_new = 0.5410077974025174\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 1 step\n",
            "Delta Q = 0.9549788421633447\n",
            "Q_table[3,3]_old = 0.5416242821063629\n",
            "Q_table[(3, 3)]_new = 0.5424406960590713\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 2 step\n",
            "Delta Q = 0.9619794591656188\n",
            "Q_table[3,0]_old = 0.6108760240371627\n",
            "Q_table[(3, 0)]_new = 0.6117678807990652\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 3 step\n",
            "Delta Q = 0.9550591092719158\n",
            "Q_table[2,2]_old = 0.5446475394191025\n",
            "Q_table[(2, 2)]_new = 0.5452418947491081\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 4 step\n",
            "Delta Q = 0.9550591092719158\n",
            "Q_table[3,3]_old = 0.5424406960590713\n",
            "Q_table[(3, 3)]_new = 0.54325573572508\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 0 step\n",
            "Delta Q = 0.9550591092719158\n",
            "Q_table[0,2]_old = 0.5410077974025174\n",
            "Q_table[(0, 2)]_new = 0.5419661269341816\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 1 step\n",
            "Delta Q = 0.9619794591656188\n",
            "Q_table[3,0]_old = 0.6117678807990652\n",
            "Q_table[(3, 0)]_new = 0.6125705518847775\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 2 step\n",
            "Delta Q = 0.9692200023219257\n",
            "Q_table[2,1]_old = 0.6886606573957638\n",
            "Q_table[(2, 1)]_new = 0.6890145939781132\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 0 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[0,0]_old = 0.544282308845372\n",
            "Q_table[(0, 0)]_new = 0.5447767575771196\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 1 step\n",
            "Delta Q = 0.9608310242811706\n",
            "Q_table[1,1]_old = 0.5984533158057745\n",
            "Q_table[(1, 1)]_new = 0.5994390085063677\n",
            "We are on 1 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 2 step\n",
            "Delta Q = 0.9549226796162849\n",
            "Q_table[5,3]_old = 0.535208864833601\n",
            "Q_table[(5, 3)]_new = 0.5366106579665257\n",
            "We are on 5 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 3 step\n",
            "Delta Q = 0.9620113134580301\n",
            "Q_table[1,2]_old = 0.6090890172786141\n",
            "Q_table[(1, 2)]_new = 0.6101914290087829\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 4 step\n",
            "Delta Q = 0.9692200023219257\n",
            "Q_table[2,1]_old = 0.6890145939781132\n",
            "Q_table[(2, 1)]_new = 0.6893331369022275\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 0 step\n",
            "Delta Q = 0.9692200023219257\n",
            "Q_table[0,1]_old = 0.6859038795305261\n",
            "Q_table[(0, 1)]_new = 0.6865334938993992\n",
            "We are on 0 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 1 step\n",
            "Delta Q = 0.977498302266345\n",
            "Q_table[6,1]_old = 0.7691111369102859\n",
            "Q_table[(6, 1)]_new = 0.7696983254856022\n",
            "We are on 6 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 2 step\n",
            "Delta Q = 0.98817519963686\n",
            "Q_table[10,1]_old = 0.8610922474038328\n",
            "Q_table[(10, 1)]_new = 0.8631582223003095\n",
            "We are on 10 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 3 step\n",
            "Delta Q = 0.98817519963686\n",
            "Q_table[14,1]_old = 0.8182182999385371\n",
            "Q_table[(14, 1)]_new = 0.8245716695815434\n",
            "We are on 14 state\n",
            "And now we are on 14 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 4 step\n",
            "Delta Q = 0.9776842400070279\n",
            "Q_table[14,3]_old = 0.6217120203536932\n",
            "Q_table[(14, 3)]_new = 0.6372250583253518\n",
            "We are on 14 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 5 step\n",
            "Delta Q = 0.9668102291265098\n",
            "Q_table[10,0]_old = 0.6118084768356232\n",
            "Q_table[(10, 0)]_new = 0.6174378582785707\n",
            "We are on 10 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 6 step\n",
            "Delta Q = 0.938488332827263\n",
            "Q_table[9,0]_old = 0.29993747308743507\n",
            "Q_table[(9, 0)]_new = 0.3084320586059545\n",
            "We are on 9 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 7 step\n",
            "Delta Q = 0.938488332827263\n",
            "Q_table[8,0]_old = 0.16212061986718115\n",
            "Q_table[(8, 0)]_new = 0.18439689070772597\n",
            "We are on 8 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 0 step\n",
            "Delta Q = 0.95513134966963\n",
            "Q_table[0,2]_old = 0.5419661269341816\n",
            "Q_table[(0, 2)]_new = 0.5429008639103934\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 1 step\n",
            "Delta Q = 0.9620399823212005\n",
            "Q_table[3,0]_old = 0.6125705518847775\n",
            "Q_table[(3, 0)]_new = 0.6133534790175003\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 2 step\n",
            "Delta Q = 0.9620399823212005\n",
            "Q_table[2,3]_old = 0.6131212298025935\n",
            "Q_table[(2, 3)]_new = 0.6138490891435346\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 3 step\n",
            "Delta Q = 0.9692728492937043\n",
            "Q_table[2,1]_old = 0.6893331369022275\n",
            "Q_table[(2, 1)]_new = 0.6896726725057091\n",
            "We are on 2 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 0 step\n",
            "Delta Q = 0.955201813111575\n",
            "Q_table[0,2]_old = 0.5429008639103934\n",
            "Q_table[(0, 2)]_new = 0.5438125906309291\n",
            "We are on 0 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,1]_old = 0.0\n",
            "Q_table[(3, 1)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyucyBIFf_Rt",
        "outputId": "857c9317-7918-4f86-9c0d-e809c0659dd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "EXgGYNNEgDFt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "bMvSq0Ptgb3L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "j1sjmJCWgj7n",
        "outputId": "dae6f858-a62e-4fdf-b4cd-12a34f5b891d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/imageio/plugins/pillow.py:409: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}